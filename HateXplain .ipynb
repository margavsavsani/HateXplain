{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git lfs install\n",
        "!git clone https://github.com/margavsavsani/HateXplain\n",
        "!pip install ekphrasis\n",
        "!pip install transformers\n",
        "!pip install GPUtil\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "mz7AV7J1FJO4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd HateXplain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8unlTO_9UGf",
        "outputId": "d97bb21d-0283-444b-f080-3b310cced0b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HateXplain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from Models.bertModels import *\n",
        "from Models.utils import *\n",
        "from Preprocess.attentionCal import *\n",
        "from Preprocess.dataCollect import *\n",
        "from Preprocess.preProcess import *\n",
        "from Preprocess.spanMatcher import *\n",
        "from TensorDataset.dataLoader import *\n",
        "from TensorDataset.datsetSplitter import *\n",
        "from manual_training_inference import *\n",
        "from predict_single import *"
      ],
      "metadata": {
        "id": "F909dTRki21O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_data={\n",
        "    'include_special':False, \n",
        "    # 'bert_tokens':False,\n",
        "    'bert_tokens':True,\n",
        "    'type_attention':'softmax',\n",
        "    'set_decay':0.1,\n",
        "    'majority':2,\n",
        "    'max_length':128,\n",
        "    'variance':5,\n",
        "    'window':4,\n",
        "    'alpha':0.5,\n",
        "    'p_value':0.8,\n",
        "    'method':'additive',\n",
        "    'decay':False,\n",
        "    'normalized':False,\n",
        "    'not_recollect':True,\n",
        "}\n",
        "\n",
        "common_hp={\n",
        "    'is_model':True,\n",
        "    'logging':'local',  ###neptune /local\n",
        "    'learning_rate':2e-5,  ### learning rate 2e-5 for bert 0.001 for gru\n",
        "    'epsilon':1e-8,\n",
        "    'batch_size':16,\n",
        "    'to_save':True,\n",
        "    'epochs':2,\n",
        "    'auto_weights':True,\n",
        "    'weights':[1.0795518,0.82139814,1.1678787 ],\n",
        "    'model_name':'birnn',\n",
        "    'random_seed':42,\n",
        "    'num_classes':3,\n",
        "    'att_lambda':0.001,\n",
        "    # 'device':'cuda',\n",
        "    'device':'cud',\n",
        "    'train_att':True\n",
        "\n",
        "}\n",
        "    \n",
        "    \n",
        "params_bert={\n",
        "    'path_files':'bert-base-uncased',\n",
        "    'what_bert':'weighted',\n",
        "    'save_only_bert':False,\n",
        "    'supervised_layer_pos':11,\n",
        "    'num_supervised_heads':6,\n",
        "    'dropout_bert':0.1\n",
        " }\n",
        "\n",
        "\n",
        "params_other = {\n",
        "        \"vocab_size\": 0,\n",
        "        \"padding_idx\": 0,\n",
        "        \"hidden_size\":64,\n",
        "        \"embed_size\":0,\n",
        "        \"embeddings\":None,\n",
        "        \"drop_fc\":0.2,\n",
        "        \"drop_embed\":0.2,\n",
        "        \"drop_hidden\":0.1,\n",
        "        \"train_embed\":False,\n",
        "        \"seq_model\":\"gru\",\n",
        "        \"attention\":\"softmax\"\n",
        "}\n",
        "\n",
        "\n",
        "if(params_data['bert_tokens']):\n",
        "    for key in params_other:\n",
        "        params_other[key]='N/A'\n",
        "else:\n",
        "    for key in params_bert:\n",
        "        params_bert[key]='N/A'\n",
        "\n",
        "\n",
        "def Merge(dict1, dict2,dict3, dict4): \n",
        "    res = {**dict1, **dict2,**dict3, **dict4} \n",
        "    return res \n",
        "\n",
        "params = Merge(params_data,common_hp,params_bert,params_other)\n",
        "\n",
        "\n",
        "dict_data_folder={\n",
        "      '2':{'data_file':'Data/dataset.json','class_label':'Data/classes_two.npy'},\n",
        "      '3':{'data_file':'Data/dataset.json','class_label':'Data/classes.npy'}\n",
        "}"
      ],
      "metadata": {
        "id": "Zzp2wlKfszSj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params['variance']=5\n",
        "params['epochs']=2\n",
        "params['to_save']=False\n",
        "params['num_classes']=3\n",
        "params['data_file']=dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names']=dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "if(params['num_classes']==2 and (params['auto_weights']==False)):\n",
        "      params['weights']=[1.0,1.0]\n",
        "        \n",
        "#for att_lambda in [0.001,0.01,0.1,1,10,100]\n",
        "params['att_lambda']=0.001\n",
        "\n",
        "params['device']='cuda'"
      ],
      "metadata": {
        "id": "M64_zQ6Jvejh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "if torch.cuda.is_available() and params['device']=='cuda':    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    ##### You can set the device manually if you have only one gpu\n",
        "    ##### comment this line if you don't want to manually set the gpu\n",
        "    deviceID = get_gpu()\n",
        "    torch.cuda.set_device(deviceID[0])\n",
        "    ##### comment this line if you don't want to manually set the gpu\n",
        "    #### parameter required is the gpu id\n",
        "    #torch.cuda.set_device(0)\n",
        "    \n",
        "else:\n",
        "    print('Since you dont want to use GPU, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSquWw1CvwPE",
        "outputId": "112c9698-407d-4443-b514-da41849b5fe7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Found a gpu\n",
            "We will use the GPU: 0 Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_model(params,device)"
      ],
      "metadata": {
        "id": "P2ENtWgFvyT-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from prettytable import PrettyTable\n",
        "\n",
        "# def count_parameters(model):\n",
        "#     table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "#     total_params = 0\n",
        "#     for name, parameter in model.named_parameters():\n",
        "#         if not parameter.requires_grad: continue\n",
        "#         params = parameter.numel()\n",
        "#         table.add_row([name, params])\n",
        "#         total_params+=params\n",
        "#     print(table)\n",
        "#     print(f\"Total Trainable Params: {total_params}\")\n",
        "#     return total_params"
      ],
      "metadata": {
        "id": "pLQiTwbfAcUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params[\"variance\"]=4"
      ],
      "metadata": {
        "id": "mw2kQEfwX5nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axWENf023GU_",
        "outputId": "a63f3a21-3435-48db-ce38-984854f4746d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import HTML as html_print\n",
        "def cstr(s, color='white'):\n",
        "  return \"<text style=color:{}>{}</text>\".format(color, s)\n",
        "def display_results(classes, norm_attn):\n",
        "  idx = np.argpartition(norm_attn, -4)[-4:]\n",
        "  our_rationales = idx[np.argsort(-norm_attn[idx])]\n",
        "\n",
        "  print(f\"      Label : {classes}\\n\")\n",
        "  display(pd.DataFrame([(sentence[i], norm_attn[i]) for i in our_rationales], columns=['rationale', 'attention']))\n",
        "  print('\\n')\n",
        "\n",
        "  marked_sentence = []\n",
        "  for i in range(len(sentence)):\n",
        "    word = sentence[i]\n",
        "    if i in our_rationales:\n",
        "      marked_sentence.append(cstr(word, color='lime'))\n",
        "    else:\n",
        "      marked_sentence.append(word)\n",
        "  return html_print(cstr(' '.join(marked_sentence)))"
      ],
      "metadata": {
        "id": "d34Cd0pGCngT"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample toxic entries to demo on, picked from the hate-xplain dataset itself:\n",
        "sample = [\n",
        "    'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches',\n",
        "    'tired i can not support abortion from a moral standpoint wired i can support it morally easy stop looking as those little niglets as future doctors and see them for what they really are future rapists of white women and future welfare recipient of white tax dollars and future democrat voters',\n",
        "    'all of my exes were cute but they were whores i guess i only attract fly looking thots',\n",
        "]"
      ],
      "metadata": {
        "id": "jM2Po8xuMsL5"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# sentence = word_tokenize(sample[0])\n",
        "sentence = word_tokenize(\"the jews are again using holohoax as an excuse  to spread their agenda hitler should have eradicated them\")\n",
        "_, classes, attn_values = pred_model(params,device,sentence)\n",
        "norm_attn = np.array([(attn)/sum(attn_values) for attn in attn_values])"
      ],
      "metadata": {
        "id": "b_FAbZiVANvK"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_results(classes, norm_attn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nE7eNtYOA2b6",
        "outputId": "fd7537e3-3762-4498-8822-8c4f45080837"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label : offensive\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  rationale  attention\n",
              "0  holohoax   0.206409\n",
              "1      jews   0.159623\n",
              "2       are   0.093108\n",
              "3    hitler   0.086157"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d665308-1b42-4922-a63a-e0dc2f560abb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rationale</th>\n",
              "      <th>attention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>holohoax</td>\n",
              "      <td>0.206409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jews</td>\n",
              "      <td>0.159623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>are</td>\n",
              "      <td>0.093108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hitler</td>\n",
              "      <td>0.086157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d665308-1b42-4922-a63a-e0dc2f560abb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d665308-1b42-4922-a63a-e0dc2f560abb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d665308-1b42-4922-a63a-e0dc2f560abb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:white>the <text style=color:lime>jews</text> <text style=color:lime>are</text> again using <text style=color:lime>holohoax</text> as an excuse to spread their agenda <text style=color:lime>hitler</text> should have eradicated them</text>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ox623hONBkS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}